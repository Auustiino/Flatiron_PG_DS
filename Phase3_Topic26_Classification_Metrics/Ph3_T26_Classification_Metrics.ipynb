{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ecaacf0c",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div style=\"color:white;\n",
    "           display:fill;\n",
    "           border-radius:5px;\n",
    "           background-color:#5642C5;\n",
    "           font-size:200%;\n",
    "           font-family:Arial;letter-spacing:0.5px\">\n",
    "\n",
    "<p width = 20%, style=\"padding: 10px;\n",
    "              color:white;\">\n",
    "Classification Metrics\n",
    "              \n",
    "</p>\n",
    "</div>\n",
    "\n",
    "Data Science Cohort Live NYC Feb 2022\n",
    "<p>Phase 3: Topic 26</p>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "<div align = \"right\">\n",
    "<img src=\"Images/flatiron-school-logo.png\" align = \"right\" width=\"200\"/>\n",
    "</div>\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "54d74557",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fba90868",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix,\\\n",
    "    precision_score, recall_score, accuracy_score, f1_score, log_loss,\\\n",
    "    roc_curve, roc_auc_score, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21e3886",
   "metadata": {
    "cell_style": "split",
    "hidden": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Many classification metrics for evaluating model validation/test set performance:\n",
    "\n",
    "- Changes which model you will pick during hyperparameter tuning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d8e1e7",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Choice of evaluation metric:\n",
    "- Major impact on how well model serves its intended goals."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9ea35c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Scenario: Identifying Fraudulent Credit Card Transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e624c762",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "credit_data = pd.read_csv('data/credit_fraud_small.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "07eb826c",
   "metadata": {
    "cell_style": "split",
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   Time    10000 non-null  float64\n",
      " 1   V1      10000 non-null  float64\n",
      " 2   V2      10000 non-null  float64\n",
      " 3   V3      10000 non-null  float64\n",
      " 4   V4      10000 non-null  float64\n",
      " 5   V5      10000 non-null  float64\n",
      " 6   V6      10000 non-null  float64\n",
      " 7   V7      10000 non-null  float64\n",
      " 8   V8      10000 non-null  float64\n",
      " 9   V9      10000 non-null  float64\n",
      " 10  V10     10000 non-null  float64\n",
      " 11  V11     10000 non-null  float64\n",
      " 12  V12     10000 non-null  float64\n",
      " 13  V13     10000 non-null  float64\n",
      " 14  V14     10000 non-null  float64\n",
      " 15  V15     10000 non-null  float64\n",
      " 16  V16     10000 non-null  float64\n",
      " 17  V17     10000 non-null  float64\n",
      " 18  V18     10000 non-null  float64\n",
      " 19  V19     10000 non-null  float64\n",
      " 20  V20     10000 non-null  float64\n",
      " 21  V21     10000 non-null  float64\n",
      " 22  V22     10000 non-null  float64\n",
      " 23  V23     10000 non-null  float64\n",
      " 24  V24     10000 non-null  float64\n",
      " 25  V25     10000 non-null  float64\n",
      " 26  V26     10000 non-null  float64\n",
      " 27  V27     10000 non-null  float64\n",
      " 28  V28     10000 non-null  float64\n",
      " 29  Amount  10000 non-null  float64\n",
      " 30  Class   10000 non-null  int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 2.4 MB\n"
     ]
    }
   ],
   "source": [
    "credit_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b87131c",
   "metadata": {
    "cell_style": "split",
    "hidden": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The dataset contains a bunch of features:\n",
    "- The transaction amount\n",
    "- The relative time of the transaction\n",
    "- 28 other features considered to be relevant. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab29a59f",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Target 'Class':\n",
    "- 1 if the transaction was fraudulent\n",
    "- 0 otherwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e4c2ac10",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "credit_data['Class'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ac077ca2",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    9962\n",
       "1      38\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "credit_data['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2267ca0b",
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "What have we just learned about our target in our dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "170820c1",
   "metadata": {},
   "source": [
    "Run a logistic regression on the credit card fraud data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ef1320f2",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=42)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separate data into feature and target DataFrames\n",
    "X = credit_data.drop('Class', axis = 1)\n",
    "y = credit_data['Class']\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.25,\n",
    "                                                   random_state=1)\n",
    "# Scale the data for modeling\n",
    "cred_scaler = StandardScaler()\n",
    "cred_scaler.fit(X_train)\n",
    "X_train_sc = cred_scaler.transform(X_train)\n",
    "X_test_sc = cred_scaler.transform(X_test)\n",
    "\n",
    "# Train a logistic regresssion model with the train data\n",
    "cred_model = LogisticRegression(random_state=42)\n",
    "cred_model.fit(X_train_sc, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf222c7",
   "metadata": {},
   "source": [
    "Remember:\n",
    "- .score(X,y) gets the accuracy of our classification model on predicting y given X."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "881d6f12",
   "metadata": {
    "cell_style": "split",
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9988"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cred_model.score(X_test_sc, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a257457a",
   "metadata": {
    "cell_style": "split",
    "hidden": true
   },
   "source": [
    "We got 99.88% accuracy! \n",
    "- Our model is good. Right?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09781e97",
   "metadata": {},
   "source": [
    "Think again."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce6c666",
   "metadata": {
    "cell_style": "split",
    "hidden": true
   },
   "source": [
    "**Accuracy** = $\\frac{TP + TN}{TP + TN + FP + FN}$\n",
    "\n",
    "- Fraction of correct classifications.\n",
    "- What the `.score()` method calculates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216025c3",
   "metadata": {
    "cell_style": "split"
   },
   "source": [
    "**Class 1 (Fraud) = Our positive class**\n",
    "\n",
    "- TP: True positive\n",
    "- FP: False positive\n",
    "- TN: True negative\n",
    "- FN: False negative"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c65ec89",
   "metadata": {},
   "source": [
    "Easy way to unpack the TP, TN, FP, FN is using the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "71451ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.metrics import plot_confusion_matrix #nice function to visualize confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8047e3fa",
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2493,    0],\n",
       "       [   3,    4]], dtype=int64)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get predictions\n",
    "y_pred = cred_model.predict(X_test_sc) \n",
    "# calculate confusion matrix\n",
    "cfmat = confusion_matrix(y_test, y_pred) \n",
    "\n",
    "cfmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f1cf84d3",
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(cred_model, \n",
    "                      X_test_sc, y_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "48eba7a1",
   "metadata": {
    "cell_style": "split",
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2493 0 3 4\n",
      "[[2493    0]\n",
      " [   3    4]]\n"
     ]
    }
   ],
   "source": [
    "tn, fn, fp, tp = cfmat.flatten()\n",
    "print(tn,fn,fp,tp)\n",
    "\n",
    "print(cfmat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "eb3114cf",
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(cred_model, \n",
    "                      X_test_sc, y_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "29c2e667",
   "metadata": {
    "cell_style": "split",
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9988\n"
     ]
    }
   ],
   "source": [
    "acc = (tp + tn) / (tp + tn + fp + fn)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b1f221",
   "metadata": {
    "cell_style": "split"
   },
   "source": [
    "My accuracy is great. But is model doing well?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa65660",
   "metadata": {
    "cell_style": "center"
   },
   "source": [
    "True positive:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72c0f39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2882dea0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d488ecb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3cee3784",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Recall** = **Sensitivity** = $\\frac{TP}{TP + FN}$\n",
    "\n",
    "In words: How many of the actually fraudulent transactions did my model identify? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7bae0d5",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_8992/196601901.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mrec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtp\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtp\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tp' is not defined"
     ]
    }
   ],
   "source": [
    "rec = tp / (tp + fn)\n",
    "print(rec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775bebbf",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Question:** Do you think a credit card company would consider recall to be an important metric? Why or why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57b9a53",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Precision** = $\\frac{TP}{TP + FP}$\n",
    "\n",
    "In words: How often was my model's prediction of 'fraudulent' correct?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7738f13",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_8992/3388691474.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtp\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtp\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tp' is not defined"
     ]
    }
   ],
   "source": [
    "prec = tp / (tp + fp)\n",
    "print(prec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3180513f",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The $F$-score is a combination of precision and recall, which can be useful when both are important for a business problem. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a975a2cd",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Most common is the **$F_1$ Score**, which is an equal balance of the two using a [harmonic mean](https://en.wikipedia.org/wiki/Harmonic_mean).\n",
    "\n",
    "$$F_1 = 2 \\frac{Pr \\cdot Rc}{Pr + Rc} = \\frac{2TP}{2TP + FP + FN}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b9533c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "f1_score = 2*prec*rec / (prec + rec)\n",
    "print(f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e2e9b0d",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Question:** Which of these metrics do you think a credit card company would care most about when trying to flag fraudulent transactions to deny?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f229b9",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## `classification_report()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2c7afc",
   "metadata": {
    "hidden": true
   },
   "source": [
    "You can get all of these metrics using the `classification_report()` function. \n",
    "\n",
    "- The top rows show statistics for if you treated each label as the \"positive\" class\n",
    "- **Support** shows the sample size in each class\n",
    "- The averages in the bottom two rows are across the rows in the class table above (useful when there are more than two classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55bfee95",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'classification_report' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10128/580191101.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'classification_report' is not defined"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84cdbe2",
   "metadata": {},
   "source": [
    "#### Exercise: Breast Cancer Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9aa613b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4c91b9",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Load the data\n",
    "preds, target = load_breast_cancer(return_X_y=True)\n",
    "\n",
    "# Split into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(preds, target,\n",
    "                                                   random_state=42)\n",
    "\n",
    "# Scale the data\n",
    "bc_scaler = StandardScaler()\n",
    "bc_scaler.fit(X_train)\n",
    "X_train_sc = bc_scaler.transform(X_train)\n",
    "X_test_sc = bc_scaler.transform(X_test)\n",
    "\n",
    "# Run the model\n",
    "bc_model = LogisticRegression(solver='lbfgs', max_iter=10000,\n",
    "                           random_state=42)\n",
    "bc_model.fit(X_train_sc, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2db002",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Calculate the following for this model:\n",
    "\n",
    "- Confusion Matrix\n",
    "- Accuracy\n",
    "- Precision\n",
    "- Recall\n",
    "- F1 Score\n",
    "\n",
    "Discuss: Which one would you choose to evaluate the model for use as a diagnostic tool to detect breast cancer? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ccc516",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Summary: Which Metric Should I Care About?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb765955",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Well, it depends.\n",
    "\n",
    "Accuracy:\n",
    "- Pro: Takes into account both false positives and false negatives.\n",
    "- Con: Can be misleadingly high when there is a significant class imbalance. (A lottery-ticket predictor that *always* predicts a loser will be highly accurate.)\n",
    "\n",
    "Recall:\n",
    "- Pro: Highly sensitive to false negatives.\n",
    "- Con: No sensitivity to false positives.\n",
    "\n",
    "Precision:\n",
    "- Pro: Highly sensitive to false positives.\n",
    "- Con: No sensitivity to false negatives.\n",
    "\n",
    "F-1 Score:\n",
    "- Harmonic mean of recall and precision.\n",
    "\n",
    "The nature of your business problem will help you determine which metric matters.\n",
    "\n",
    "Sometimes false positives are much worse than false negatives: Arguably, a model that compares a sample of crime-scene DNA with the DNA in a city's database of its citizens presents one such case. Here a false positive would mean falsely identifying someone as having been present at a crime scene, whereas a false negative would mean only that we fail to identify someone who really was present at the crime scene as such.\n",
    "\n",
    "On the other hand, consider a model that inputs X-ray images and predicts the presence of cancer. Here false negatives are surely worse than false positives: A false positive means only that someone without cancer is misdiagnosed as having it, while a false negative means that someone with cancer is misdiagnosed as *not* having it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039230e4",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Multiclass Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ec277a",
   "metadata": {
    "hidden": true
   },
   "source": [
    "What if our target has more than two classes?\n",
    "\n",
    "**Multiclass classification** problems have more than two possible values for the target. For example, your target would have 10 possible values if you were trying to [classify an image of a hand-written number as a digit from 0 to 9](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_digits.html). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d409ac",
   "metadata": {
    "hidden": true
   },
   "source": [
    "In these cases, we can use the same methods to evaluate our models. Confusion matrices will no longer be 2x2, but will have a number of rows/columns equal to the number of classes. \n",
    "\n",
    "When calculating metrics like precision, we choose one class to be the \"positive\" class, and the rest are assigned to the \"negative\" class. "
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
