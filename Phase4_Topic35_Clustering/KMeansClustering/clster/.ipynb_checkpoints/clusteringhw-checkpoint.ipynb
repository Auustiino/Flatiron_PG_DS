{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import sys\n",
    "import random\n",
    "\n",
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "X = np.genfromtxt('data/s1cluster.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function will initialize the centroids off of the data\n",
    "\n",
    "def initialize_centroids(X, cluster_num):\n",
    "    minmaxranges = []\n",
    "    for col in X.T:\n",
    "        minmaxcolrange = [np.min(col), np.max(col)]\n",
    "        minmaxranges.append(minmaxcolrange)\n",
    "    \n",
    "    #this generates a vector within the min/max bounds of each dimension in the dataset\n",
    "    initcentroids = [ np.array([random.uniform(componentrange[0], componentrange[1]) for componentrange in minmaxranges]) for i in range(cluster_num) ]\n",
    "    \n",
    "    return initcentroids\n",
    "\n",
    "\n",
    "#outputs cluster assignment for each observation in dataset (index in centroidlist)\n",
    "def clusterassign(X, centroidlist):\n",
    "    \n",
    "    #helper function creates a numpy vector calculating L2 distance squared between x and each of the centroids\n",
    "    def vecclusterassign(x, centroidlist):\n",
    "        distlist = [ np.dot((x - centroid), (x - centroid)) for centroid in centroidlist ]\n",
    "        return np.argmin(distlist)\n",
    "    \n",
    "    clust_assignlist = [vecclusterassign(x, centroidlist) for x in X] \n",
    "    \n",
    "    return np.array(clust_assignlist)\n",
    "\n",
    "# assign_list is list of cluster assignments for each observation in X \n",
    "def calc_clustermeans(X, assign_list):\n",
    "    newcentroidlist = [np.average( X[np.where(assign_list == clust_identifier)[0]], axis = 0) for clust_identifier in np.unique(assign_list)]\n",
    "    return newcentroidlist\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = initialize_centroids(X, 5)\n",
    "m = clusterassign(X, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KMeans(X, clust_num, iter_num):\n",
    "    \n",
    "    iterations = 0\n",
    "    current_centroid = initialize_centroids(X, clust_num)\n",
    "    \n",
    "    \n",
    "    # for assignment we do 10 iterations, but in practice will be a more general stopping condition\n",
    "    while (iterations < iter_num):\n",
    "        # assign cluster \n",
    "        current_assignment = clusterassign(X, current_centroid)\n",
    "        \n",
    "        # now update current centroid\n",
    "        current_centroid = calc_clustermeans(X, current_assignment)\n",
    "        centroid_outputter = np.array(current_centroid)\n",
    "        \n",
    "        filename = \"centroids-\" + str(iterations+1) + \".csv\" #\"i\" would be each iteration\n",
    "        np.savetxt(filename, centroid_outputter, delimiter=\",\")\n",
    "        \n",
    "        iterations +=1\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#h = KMeans(X, 15, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize means\n",
    "def initialize_means(X, cluster_num):\n",
    "    minmaxranges = []\n",
    "    for col in X.T:\n",
    "        minmaxcolrange = [np.min(col), np.max(col)]\n",
    "        minmaxranges.append(minmaxcolrange)\n",
    "    \n",
    "    #this generates a vector within the min/max bounds of each dimension in the dataset\n",
    "    initcentroids = np.array([ np.array([random.uniform(componentrange[0], componentrange[1]) for componentrange in minmaxranges]) for i in range(cluster_num) ])\n",
    "    \n",
    "    return initcentroids\n",
    "#--------------------------------------------------------------------------------------------------------------------------------------\n",
    "#cluster_posterior is our q-distribution over which we take the expectation of the joint distribution on x and its cluster assignment\n",
    "\n",
    "def cluster_posterior(x, pi, clust_means, clust_covars):\n",
    "    \n",
    "    clusternums = len(pi)\n",
    "    norm = sum([ pi[j] * multivariate_normal.pdf(x, mean = clust_means[j], cov = clust_covars[j]) for j in range(clusternums)])\n",
    "    \n",
    "    if norm == 0.0:\n",
    "        return (1/clusternums)*np.ones(clusternums)\n",
    "    else:\n",
    "        posterior = np.array([(1/norm) * clust_prob[k] * multivariate_normal.pdf(x, mean = clust_means[k], cov = clust_covars[k]) for k in clusternums])\n",
    "        \n",
    "    return posterior\n",
    "\n",
    "#----------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "#given the current cluster probabilities, cluster means, cluster covariances: maximize q-expectation of joint distribution of X and cluster assignment\n",
    "#output new point estimates of cluster probabilities, cluster means, cluster covariances\n",
    "\n",
    "def Mstepupdate(X, clust_prob, clust_means, clust_covars):\n",
    "    n = len(X)\n",
    "    d = len(X.T)\n",
    "\n",
    "    #initializes new cluster probability, cluster mean, and covariance lists\n",
    "    Pi = []\n",
    "    clust_mu = []\n",
    "    clust_sigmas = []\n",
    "    \n",
    "    for k in np.arange(len(clust_prob)):\n",
    "        # outputs Pi_k for kth cluster and calculates n_k\n",
    "        nk = sum([cluster_posterior(x, k, clust_prob, clust_means, clust_covars) for x in X ])\n",
    "        Pi.append(nk / n)\n",
    "        \n",
    "        #outputs new mean for kth cluster\n",
    "        mu_k = (1 / nk)* sum( [ cluster_posterior(x, k, clust_prob, clust_means, clust_covars)*x for x in X ] )\n",
    "        clust_mu.append(mu_k)\n",
    "        \n",
    "        #ouputs new covariance matrix for kth cluster\n",
    "        Sigma_k = (1 / nk)* sum( [cluster_posterior(x, k, clust_prob, clust_means, clust_covars)*np.outer( (x - mu_k) , (x - mu_k) ) for x in X] )\n",
    "        clust_sigmas.append(Sigma_k)\n",
    "    \n",
    "    return Pi, clust_mu, clust_sigmas\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "#EM_GMM(X, 15, 1)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define main GMM algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EM_GMM(X, clust_num, iter_num):\n",
    "    \n",
    "    d = np.shape(X)[1]\n",
    "    n = np.shape(X)[0]\n",
    "    \n",
    "    # initialize Gaussian mixture distribution parameters -- python list format\n",
    "    iterations = 0\n",
    "    \n",
    "    pi = (1/clust_num)*np.ones(clust_num) # initialize uniform cluster probability\n",
    "    \n",
    "    cluster_means = initialize_means(X, clust_num) #takes data and initializes cluster means based off of dataset limits\n",
    "    \"\"\"\"\n",
    "    cluster_sigmas = [np.identity(d) for k in np.arange(clust_num) ]\n",
    "    \n",
    "    while (iterations < iter_num ):\n",
    "        #M-step updates (E-step hidden inside via inner call to cluster-posterior )\n",
    "        cluster_proba, cluster_means, cluster_sigmas = Mstepupdate(X, cluster_proba, cluster_means, cluster_sigmas)\n",
    "        \n",
    "        # convert new Gaussian mixture parameters to correct output format\n",
    "        pi_ouputter = np.array(cluster_proba)\n",
    "        means_outputter = np.array(cluster_means)\n",
    "        \n",
    "            \n",
    "        filename = \"pi-\" + str(iterations+1) + \".csv\" \n",
    "        np.savetxt(filename, pi_outputter, delimiter=\",\") \n",
    "        \n",
    "        filename = \"mu-\" + str(iterations+1) + \".csv\"\n",
    "        np.savetxt(filename, means_outputter, delimiter=\",\")\n",
    "        \n",
    "        for j in np.arange(len(cluster_sigmas)):\n",
    "            filename = \"Sigma-\" + str(j+1) + \"-\" + str(iterations+1) + \".csv\"\n",
    "            np.savetxt(filename, cluster_sigmas[j], delimiter = \",\")\n",
    "        \n",
    "        iterations += 1\n",
    "        \n",
    "        \"\"\"\n",
    "    print(cluster_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15915494309189535"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "multivariate_normal.pdf([555000,130000], mean = [555000,130000], cov = np.identity(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[586736.3097070223   730629.789605211   ]\n",
      " [284220.27983774414  546509.5503852363  ]\n",
      " [158143.29017728544  808683.1632292408  ]\n",
      " [ 25514.712740782146 367402.5337826628  ]\n",
      " [539895.293584768    173951.6728083283  ]\n",
      " [624151.920715032    752796.4546158852  ]\n",
      " [766537.4941715605    71288.36336425233 ]\n",
      " [213535.72117586804  954569.8329605921  ]\n",
      " [365017.2843011949   843156.3242977345  ]\n",
      " [728352.2957706093   657195.486801179   ]\n",
      " [289243.5240510221   501359.74083790166 ]\n",
      " [474959.32811422215  488709.6590400039  ]\n",
      " [381413.1824704577   817942.533729387   ]\n",
      " [253635.27137001345  593475.2117256045  ]\n",
      " [593974.3625685638    87695.39049013663 ]]\n"
     ]
    }
   ],
   "source": [
    "EM_GMM(X,15,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pi' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-f84ab820532c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpi\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'pi' is not defined"
     ]
    }
   ],
   "source": [
    "pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ColumbiaMLEDX",
   "language": "python",
   "name": "columbiamledx"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
