{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import sys\n",
    "from numpy.random import uniform\n",
    "\n",
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "X = np.genfromtxt('data/s1cluster.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.37023551, 1.39084976, 1.54583783, 1.97525242, 1.32077845])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniform(0,2, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[664159. 665845. 597173. ... 650661. 599647. 684091.]\n",
      "0\n",
      "[550946. 557965. 575538. ... 861267. 858702. 842566.]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "for i, col in enumerate(X.T):\n",
    "    print(col)\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[     0.,      0.],\n",
       "       [ 19835., 961951.],\n",
       "       [ 51121., 970756.]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    minmaxrange = np.zeros(X.shape[1]).reshape(1,-1)\n",
    "    for col in X.T:\n",
    "        ranger = np.array([np.min(col), np.max(col)])\n",
    "        minmaxrange = np.concatenate((minmaxrange, [ranger]))\n",
    "    minmaxrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[19835.0, 961951.0],\n",
       "       [51121.0, 970756.0]], dtype=object)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minmaxrange[1::]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "for component in minmaxranges:\n",
    "    rand_feat_val = uniform(component[0], component[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function will initialize the centroids off of the data\n",
    "\n",
    "def initialize_centroids(X, cluster_num):\n",
    "    minmaxrange = np.zeros(X.shape[1]).reshape(1,-1)\n",
    "    for col in X.T:\n",
    "        ranger = np.array([np.min(col), np.max(col)])\n",
    "        minmaxrange = np.concatenate((minmaxrange, [ranger]))\n",
    "    minmaxrange = minmaxrange[1::] #list of min/max ranges for each feature\n",
    "    \n",
    "    \n",
    "    #this generates a vector within the min/max bounds of each dimension in the dataset\n",
    "    initcentroids = np.zeros(cluster_num).reshape(1,-1)\n",
    "    for feat_min, feat_max in minmaxrange:\n",
    "        featclusterlist = uniform( feat_min, feat_max , size = cluster_num) #random initialization of feature\n",
    "        initcentroids = np.concatenate((initcentroids, [featclusterlist]))\n",
    "    \n",
    "    return initcentroids[1::].T\n",
    "\n",
    "\n",
    "#outputs cluster assignment for each observation in dataset (index in centroidlist)\n",
    "def clusterassign(X, centroidlist):\n",
    "    \n",
    "    #helper function to cluster assign for a given data point\n",
    "    def vecclusterassign(x, centroidlist):\n",
    "        #calculate squared distance of point to each centroid\n",
    "        distlist = [ np.dot((x - centroid), (x - centroid)) for centroid in centroidlist ] \n",
    "        return np.argmin(distlist) # gets centroid with minimum distance\n",
    "    \n",
    "    clust_assignlist = np.array([vecclusterassign(x, centroidlist) for x in X])  # cluster assignment for each data point\n",
    "    \n",
    "    return np.array(clust_assignlist)\n",
    "\n",
    "# takes \n",
    "def calc_clustermeans(X, assign_list):\n",
    "    newcentroidlist = [np.average( X[np.where(assign_list == clust_identifier)[0]], axis = 0) for clust_identifier in np.unique(assign_list)]\n",
    "    return newcentroidlist\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[483288.91493387, 483053.46833862],\n",
       "       [535223.45666312, 246765.12263975],\n",
       "       [877258.26325105, 413632.81018074],\n",
       "       [850728.57638637, 391345.5242613 ],\n",
       "       [674449.45918955, 472304.33600624]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initialize_centroids(X, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = initialize_centroids(X, 5)\n",
    "m = clusterassign(X, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KMeans(X, clust_num, iter_num):\n",
    "    \n",
    "    iterations = 0\n",
    "    current_centroid = initialize_centroids(X, clust_num)\n",
    "    \n",
    "    \n",
    "    # for assignment we do 10 iterations, but in practice will be a more general stopping condition\n",
    "    while (iterations < iter_num):\n",
    "        # assign cluster \n",
    "        current_assignment = clusterassign(X, current_centroid)\n",
    "        \n",
    "        # now update current centroid\n",
    "        current_centroid = calc_clustermeans(X, current_assignment)\n",
    "        centroid_outputter = np.array(current_centroid)\n",
    "        \n",
    "        filename = \"centroids-\" + str(iterations+1) + \".csv\" #\"i\" would be each iteration\n",
    "        np.savetxt(filename, centroid_outputter, delimiter=\",\")\n",
    "        \n",
    "        iterations +=1\n",
    "    \n",
    "    return centroid_outputter, current_assignment\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[540103.01652893, 579410.76033058],\n",
       "        [168295.41492537, 347724.81791045],\n",
       "        [244069.21238938, 847518.09144543],\n",
       "        [320318.89085546, 161713.24483776],\n",
       "        [859007.16571429, 552562.2       ],\n",
       "        [825294.3974359 , 372653.30769231],\n",
       "        [805371.30321593, 240956.04287902],\n",
       "        [822447.65472313, 734224.9771987 ],\n",
       "        [621610.03537736, 489045.01650943],\n",
       "        [417332.14240506, 787518.76265823],\n",
       "        [670929.06818182, 862765.73295455],\n",
       "        [154248.22077922, 557568.4961039 ],\n",
       "        [509216.3933518 , 179463.26869806],\n",
       "        [380289.215625  , 469141.825     ]]),\n",
       " array([ 8,  8,  8, ..., 10, 10, 10], dtype=int64))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KMeans(X, 15, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize means\n",
    "def initialize_means(X, cluster_num):\n",
    "    minmaxranges = []\n",
    "    for col in X.T:\n",
    "        minmaxcolrange = [np.min(col), np.max(col)]\n",
    "        minmaxranges.append(minmaxcolrange)\n",
    "    \n",
    "    #this generates a vector within the min/max bounds of each dimension in the dataset\n",
    "    initcentroids = np.array([ np.array([random.uniform(componentrange[0], componentrange[1]) for componentrange in minmaxranges]) for i in range(cluster_num) ])\n",
    "    \n",
    "    return initcentroids\n",
    "#--------------------------------------------------------------------------------------------------------------------------------------\n",
    "#cluster_posterior is our q-distribution over which we take the expectation of the joint distribution on x and its cluster assignment\n",
    "\n",
    "def cluster_posterior(x, pi, clust_means, clust_covars):\n",
    "    \n",
    "    clusternums = len(pi)\n",
    "    norm = sum([ pi[j] * multivariate_normal.pdf(x, mean = clust_means[j], cov = clust_covars[j]) for j in range(clusternums)])\n",
    "    \n",
    "    if norm == 0.0:\n",
    "        return (1/clusternums)*np.ones(clusternums)\n",
    "    else:\n",
    "        posterior = np.array([(1/norm) * clust_prob[k] * multivariate_normal.pdf(x, mean = clust_means[k], cov = clust_covars[k]) for k in clusternums])\n",
    "        \n",
    "    return posterior\n",
    "\n",
    "#----------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "#given the current cluster probabilities, cluster means, cluster covariances: maximize q-expectation of joint distribution of X and cluster assignment\n",
    "#output new point estimates of cluster probabilities, cluster means, cluster covariances\n",
    "\n",
    "def Mstepupdate(X, clust_prob, clust_means, clust_covars):\n",
    "    n = len(X)\n",
    "    d = len(X.T)\n",
    "\n",
    "    #initializes new cluster probability, cluster mean, and covariance lists\n",
    "    Pi = []\n",
    "    clust_mu = []\n",
    "    clust_sigmas = []\n",
    "    \n",
    "    for k in np.arange(len(clust_prob)):\n",
    "        # outputs Pi_k for kth cluster and calculates n_k\n",
    "        nk = sum([cluster_posterior(x, k, clust_prob, clust_means, clust_covars) for x in X ])\n",
    "        Pi.append(nk / n)\n",
    "        \n",
    "        #outputs new mean for kth cluster\n",
    "        mu_k = (1 / nk)* sum( [ cluster_posterior(x, k, clust_prob, clust_means, clust_covars)*x for x in X ] )\n",
    "        clust_mu.append(mu_k)\n",
    "        \n",
    "        #ouputs new covariance matrix for kth cluster\n",
    "        Sigma_k = (1 / nk)* sum( [cluster_posterior(x, k, clust_prob, clust_means, clust_covars)*np.outer( (x - mu_k) , (x - mu_k) ) for x in X] )\n",
    "        clust_sigmas.append(Sigma_k)\n",
    "    \n",
    "    return Pi, clust_mu, clust_sigmas\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "#EM_GMM(X, 15, 1)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define main GMM algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EM_GMM(X, clust_num, iter_num):\n",
    "    \n",
    "    d = np.shape(X)[1]\n",
    "    n = np.shape(X)[0]\n",
    "    \n",
    "    # initialize Gaussian mixture distribution parameters -- python list format\n",
    "    iterations = 0\n",
    "    \n",
    "    pi = (1/clust_num)*np.ones(clust_num) # initialize uniform cluster probability\n",
    "    \n",
    "    cluster_means = initialize_means(X, clust_num) #takes data and initializes cluster means based off of dataset limits\n",
    "    \"\"\"\"\n",
    "    cluster_sigmas = [np.identity(d) for k in np.arange(clust_num) ]\n",
    "    \n",
    "    while (iterations < iter_num ):\n",
    "        #M-step updates (E-step hidden inside via inner call to cluster-posterior )\n",
    "        cluster_proba, cluster_means, cluster_sigmas = Mstepupdate(X, cluster_proba, cluster_means, cluster_sigmas)\n",
    "        \n",
    "        # convert new Gaussian mixture parameters to correct output format\n",
    "        pi_ouputter = np.array(cluster_proba)\n",
    "        means_outputter = np.array(cluster_means)\n",
    "        \n",
    "            \n",
    "        filename = \"pi-\" + str(iterations+1) + \".csv\" \n",
    "        np.savetxt(filename, pi_outputter, delimiter=\",\") \n",
    "        \n",
    "        filename = \"mu-\" + str(iterations+1) + \".csv\"\n",
    "        np.savetxt(filename, means_outputter, delimiter=\",\")\n",
    "        \n",
    "        for j in np.arange(len(cluster_sigmas)):\n",
    "            filename = \"Sigma-\" + str(j+1) + \"-\" + str(iterations+1) + \".csv\"\n",
    "            np.savetxt(filename, cluster_sigmas[j], delimiter = \",\")\n",
    "        \n",
    "        iterations += 1\n",
    "        \n",
    "        \"\"\"\n",
    "    print(cluster_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15915494309189535"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "multivariate_normal.pdf([555000,130000], mean = [555000,130000], cov = np.identity(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[586736.3097070223   730629.789605211   ]\n",
      " [284220.27983774414  546509.5503852363  ]\n",
      " [158143.29017728544  808683.1632292408  ]\n",
      " [ 25514.712740782146 367402.5337826628  ]\n",
      " [539895.293584768    173951.6728083283  ]\n",
      " [624151.920715032    752796.4546158852  ]\n",
      " [766537.4941715605    71288.36336425233 ]\n",
      " [213535.72117586804  954569.8329605921  ]\n",
      " [365017.2843011949   843156.3242977345  ]\n",
      " [728352.2957706093   657195.486801179   ]\n",
      " [289243.5240510221   501359.74083790166 ]\n",
      " [474959.32811422215  488709.6590400039  ]\n",
      " [381413.1824704577   817942.533729387   ]\n",
      " [253635.27137001345  593475.2117256045  ]\n",
      " [593974.3625685638    87695.39049013663 ]]\n"
     ]
    }
   ],
   "source": [
    "EM_GMM(X,15,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pi' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-f84ab820532c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpi\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'pi' is not defined"
     ]
    }
   ],
   "source": [
    "pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "ColumbiaMLEDX",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
